Pandas For Data Science
1. INTRODUCTION TO NOTEBOOKS
INTRODUCTION TO JUPYTER NOTEBOOK
LAUNCH JUPYTER NOTEBOOK
NOTEBOOK BASICS
MARKDOWN
MARKDOWN TABLES
BEAUTIFUL MATHEMATICS TYPESETTING

2. PANDAS OVERVIEW
OBJECT CREATION
SELECTION
ASSIGNMENT STATEMENTS
MISSING DATA
OPERATIONS
MERGE: CONCAT, JOIN, APPEND
INPUT AND OUTPUT
REMOTE DATA ACCESS
GROUPING
CATEGORICALS
TIME SERIES RESAMPLING

3. SERIES
CREATE SERIES
VECTORIZED OPERATIONS
DATE ARITHMETIC

4. DATA FRAMES AND PANELS
CREATE DATA FRAMES
SELECT, ADD, AND DELETE
INDEXING AND SELECTION
NUMPY UNIVERSAL FUNCTIONS
CREATE PANELS

5. PLOTTING
INLINE PLOTTING
FIGURES AND SUBPLOTS
MULTIPLE LINES IN A SINGLE PLOT
TICK MARKS, LABELS, AND GRIDS
PLOT ANNOTATIONS
DATAFRAME PLOTS


************************************************************************************************************
1. INTRODUCTION TO NOTEBOOKS
************************************************************************************************************
INTRODUCTION TO JUPYTER NOTEBOOK
LAUNCH JUPYTER NOTEBOOK
NOTEBOOK BASICS
MARKDOWN
MARKDOWN TABLES
BEAUTIFUL MATHEMATICS TYPESETTING

************************************************************************************************************
2. PANDAS OVERVIEW
************************************************************************************************************
OBJECT CREATION
my_series = pd.Series([1,3,5,np.nan,6,8])
my_dates_index = pd.date_range('20160101', periods=6)
>>> DatetimeIndex(['2016-01-01', '2016-01-02', '2016-01-03', '2016-01-04',
               '2016-01-05', '2016-01-06'],
              dtype='datetime64[ns]', freq='D')

#Df from numpyarray
#Datetime index
sample_df = pd.DataFrame(sample_numpy_data, index=my_dates_index, columns=list('ABCD'))

#Df from dict
df_from_dictionary = pd.DataFrame({ 
                         'float' : 1.,
                         'time' : pd.Timestamp('20160825'),
                         'series' : pd.Series(1,index=list(range(4)),dtype='float32'),
                         'array' : np.array([3] * 4,dtype='int32'),
                         'categories' : pd.Categorical(["test","train","taxes","tools"]),
                         'dull' : 'boring data' 
                      })
df.dtypes
df.values
df.index
df.columns
df.describe()
	pd.set_option('display.precision', 2)
	df.describe()
df.T
#sort dataframe
df.sort_index(axis=1, ascending=False)
df.sort_values(by='B', ascending=False)

---------------------------------------------------------------
SELECTION

			A	B	C	D
2016-01-01	0	1	2	3
2016-01-02	4	5	6	7
2016-01-03	8	9	10	11
2016-01-04	12	13	14	15
2016-01-05	16	17	18	19
2016-01-06	20	21	22	23

sample_df['C']
sample_df[1:4]
sample_df['2016-01-01':'2016-01-04']


sample_df.loc[dates_index[1:3]]
sample_df.loc[:,['A','B']]
sample_df.loc['2016-01-01':'2016-01-03',['A','B']]
sample_df.loc['2016-01-03',['D','B']]


sample_df.iloc[3]
sample_df.iloc[1:3, 2:4]
sample_df.iloc[[0,1,3], [0,2]]
sample_df.iloc[1:3,:]
sample_df.iloc[:, 1:3]


sample_df.C >= 14
sample_df[sample_df >= 11]

# isin()
sample_df_2[sample_df_2['Fruits'].isin(['banana','pineapple', 'smoothy'])]

---------------------------------------------------------------
ASSIGNMENT STATEMENTS

			A	B	C	D
2016-07-01	0	1	2	3
2016-07-02	4	5	6	7
2016-07-03	8	9	10	11
2016-07-04	12	13	14	15
2016-07-05	16	17	18	19
2016-07-06	20	21	22	23
sample_df_2['Fruits'] = ['apple', 'orange','banana','strawberry','blueberry','pineapple']
			A	B	C	D	Fruits
2016-07-01	0	1	2	3	apple
2016-07-02	4	5	6	7	orange
2016-07-03	8	9	10	11	banana
2016-07-04	12	13	14	15	strawberry
2016-07-05	16	17	18	19	blueberry
2016-07-06	20	21	22	23	pineapple

#Setting Dataframe values by Series 
sample_series = pd.Series([1,2,3,4,5,6], index=pd.date_range(starting_date, periods=6))
sample_df_2['Extra Data'] = sample_series *3 +1
			A	B	C	D	Fruits		Extra Data
2016-07-01	0	1	2	3	apple		4
2016-07-02	4	5	6	7	orange		7
2016-07-03	8	9	10	11	banana		10
2016-07-04	12	13	14	15	strawberry	13
2016-07-05	16	17	18	19	blueberry	16
2016-07-06	20	21	22	23	pineapple	19

#Setting Dataframe values by label - .at['row','column']
sample_df_2.at[dates_index[3],'Fruits'] = 'pear'

#Setting Dataframe values by position - .iat[row_index,column_index]
sample_df_2.iat[3,2] = 4444

#Setting by assigning with a numpy array
sample_df_2['G'] = second_numpy_array # second_numpy_array = array([  7, 107, 207, 307, 407, 507])
>>> 
			A	B	C		D	Fruits		Extra Data	G
2016-07-01	0	1	2		3	apple		4			7
2016-07-02	4	5	6		7	orange		7			107
2016-07-03	8	9	10		11	banana		10			207
2016-07-04	12	13	4444	15	pear		13			307
2016-07-05	16	17	18		19	blueberry	16			407
2016-07-06	20	21	22		23	pineapple	19			507
------------------------------------------------------------------------------------------------------------------------------
MISSING DATA
new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10', 'Chrome']
browser_df_2 = browser_df.reindex(new_index)

				http_status	response_time
Safari			404.0		0.07
Iceweasel		NaN			NaN
Comodo Dragon	NaN			NaN
IE10			404.0		0.08
Chrome			200.0		0.02

#drop rows that have missing data
browser_df_3 = browser_df_2.dropna(how='any')
				http_status	response_time
Safari			404.0		0.07
IE10			404.0		0.08
Chrome			200.0		0.02

#fill-in missing data
browser_df_2.fillna(value=-0.05555)

#get boolean mask where values are nan
pd.isnull(browser_df_2)
				http_status	response_time
Safari			True		True
Iceweasel		False		False
Comodo Dragon	False		False
IE10			True		True


------------------------------------------------------------------------------------------------------------------------------
OPERATIONS
pd.set_option('display.precision', 2)
sample_df_2.describe()

sample_df_2.mean()

#row mean
sample_df_2.mean(1)

#apply (a function to a data frame)
sample_df_2.apply(np.cumsum, axis=0)


s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])
s.str.lower()

s.str.len()

------------------------------------------------------------------------------------------------------------------------------

MERGE: CONCAT, JOIN, APPEND
CONCAT
	pd.concat(sample_df_2[:2], sample_df_2[2:4])

APPEND
	sample_df_2.append(sample_df_2.iloc[2])

JOIN
	left = pd.DataFrame({'my_key': ['K0', 'K1', 'K2', 'K3'],
	 'A': ['A0', 'A1', 'A2', 'A3'],
	 'B': ['B0', 'B1', 'B2', 'B3']})
	right = pd.DataFrame({'my_key': ['K0', 'K1', 'K2', 'K3'],
	 'C': ['C0', 'C1', 'C2', 'C3'],
	 'D': ['D0', 'D1', 'D2', 'D3']})

	result = pd.merge(left, right, on='my_key')
			A	B	my_key	C	D
		0	A0	B0	K0		C0	D0
		1	A1	B1	K1		C1	D1
		2	A2	B2	K2		C2	D2
		3	A3	B3	K3		C3	D3

------------------------------------------------------------------------------------------------------------------------------
INPUT AND OUTPUT
#read from an Excel file
file_name_string = 'EmployeesWithGrades.xlsx'
employees_df = pd.read_excel(file_name_string, 'Sheet1', index_col=None, na_values=['NA'])
"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"

#write to a comma separated value (.csv) file
file_name_string_csv = 'EmployeesWithGrades.csv'
employees_df.to_csv(file_name_string_csv )
"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html"


------------------------------------------------------------------------------------------------------------------------------
REMOTE DATA ACCESS
!pip install pandas_datareader
%matplotlib inline
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datetime
from pandas_datareader import data, wb

"Yahoo finance"
start = datetime.datetime(2010, 1, 1)
end = datetime.datetime(2016, 7, 15)
yahoo_df = data.DataReader("F", 'yahoo', start, end)
yahoo_df.plot()

"FRED"
start = datetime.datetime(2010, 1, 1)
end = datetime.datetime(2019, 7, 15)
unrate_df = data.DataReader('GDP', 'fred', start, end)
unrate_df.plot()



------------------------------------------------------------------------------------------------------------------------------
GROUPING
one or more of the following steps:
	- Splitting the data into groups based on some criteria
	- Applying a function to each group independently
	- Combining the results into a data structure
#Specific sheet in an excel file
file_name_string = 'EmployeesWithGrades.xlsx'
employees_df = pd.read_excel(file_name_string, 'Sheet1', index_col=None, na_values=['NA'])
>>>	
	Department		Name	YearsOfService	Grade
0	Marketing		Able	4				a
1	Engineering		Baker	7				b
2	Accounting		Charlie	12				c
3	Marketing		Delta	1				d
4	Engineering		Echo	15				f
5	Accounting		Foxtrot	9				a
6	Marketing		Golf	3				b
7	Engineering		Hotel	1				c

employees_df.groupby('Department').sum()
>>>
			YearsOfService
Department	
Accounting	47
Engineering	60
Marketing	52
------------------------------------------------------------------------------------------------------------------------------
CATEGORICALS
Categoricals are a pandas data type, which correspond to categorical variables in statistics: a variable, which can take on only a limited, and usually fixed, number of possible values (categories; levels in R). Examples are gender, social class, blood types, country affiliations, observation time or ratings via Likert scales.

In contrast to statistical categorical variables, categorical data might have an order (e.g. ‘strongly agree’ vs ‘agree’ or ‘first observation’ vs. ‘second observation’), but numerical operations (additions, divisions, ...) are not possible.

All values of categorical data are either in categories or np.nan. Order is defined by the order of categories, not lexical order of the values.

#Change data type
employees_df["Grade"] = employees_df["Grade"].astype("category")
	Department	Name	YearsOfService	Grade
0	Marketing	Able	4				a
1	Engineering	Baker	7				b
2	Accounting	Charlie	12				c
3	Marketing	Delta	1				d
4	Engineering	Echo	15				f
5	Accounting	Foxtrot	9				a
6	Marketing	Golf	3				b
7	Engineering	Hotel	1				c

#Rename the categories
employees_df["Grade"].cat.categories = ["excellent", "good", "acceptable", "poor", "unacceptable"]
	Department	Name	YearsOfService	Grade
0	Marketing	Able	4				excellent
1	Engineering	Baker	7				good
2	Accounting	Charlie	12				acceptable
3	Marketing	Delta	1				poor
4	Engineering	Echo	15				unacceptable
5	Accounting	Foxtrot	9				excellent
6	Marketing	Golf	3				good
7	Engineering	Hotel	1				acceptable
#
employees_df.groupby('Grade').count()
>>>
			 Department	Name	YearsOfService
Grade		 	
excellent	 6			6		6
good		 5			5		5
acceptable	 5			5		5
poor		 5			5		5
unacceptable 5			5		5






TIME SERIES RESAMPLING

************************************************************************************************************
3. SERIES .get()
************************************************************************************************************
CREATE SERIES
Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index.

my_simple_series = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])
>>>
a    0.591872
b   -1.381102
c    2.354536
d   -1.339378
e   -1.888910
dtype: float64

my_simple_series.index

#Create series from NumPy array, without explicit index
my_simple_series = pd.Series(np.random.randn(5))
my_simple_series

#Access a series like a NumPy array
my_simple_series[:3]

#Create series from Python dictionary
my_dictionary = {'a' : 45., 'b' : -19.5, 'c' : 4444}
my_second_series = pd.Series(my_dictionary)
>>>
a      45.0
b     -19.5
c    4444.0
dtype: float64

my_second_series['b']
>>> -19.5


*NOTE* order in display; same as order in "index"

*NOTE* NaN


pd.Series(my_dictionary, index=['b', 'c', 'd', 'a'])
>>>
b     -19.5
c    4444.0
d       NaN
a      45.0
dtype: float64

my_second_series.get('a')

unknown = my_second_series.get('f')
type(unknown)


pd.Series(5., index=['a', 'b', 'c', 'd', 'e'])
a    5.0
b    5.0
c    5.0
d    5.0
e    5.0
dtype: float64




------------------------------------------------------------------------------------------------------------------------------
VECTORIZED OPERATIONS - series_.map() np.exp(series_) series_.str.lower()
- NOT necessary to write loops for element-by-element operations
- pandas` Series objects can be passed to MOST NumPy functions

my_dictionary = {'a' : 45., 'b' : -19.5, 'c' : 4444}
my_series = pd.Series(my_dictionary)
a      45.0
b     -19.5
c    4444.0
dtype: float64

my_series + my_series
a      90.0
b     -39.0
c    8888.0
dtype: float64

my_series + 5
a      50.0
b     -14.5
c    4449.0
dtype: float64


np.exp(my_series)

def multiply_by_ten (input_element):
    return input_element * 10.0
my_series.map(multiply_by_ten)

series_of_strings = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])
series_of_strings.str.lower()
0       a
1       b
2       c
3    aaba
4    baca
5     NaN
6    caba
7     dog
8     cat
dtype: object

------------------------------------------------------------------------------------------------------------------------------
DATE ARITHMETIC - now() 
Common date arithmetic operations
- calculate differences between date
- generate sequences of dates and time spans
- convert time series to a particular frequency

	to_datetime(args, *kwargs)							Convert argument to datetime.	
------------------------------------------------------------------------------------------------------------
to_timedelta(args, *kwargs)							Convert argument to timedelta	
date_range([start, end, periods, freq, tz, ...])	Return a fixed frequency datetime index, with day (calendar) as the default	
bdate_range([start, end, periods, freq, tz, ...])	Return a fixed frequency datetime index, with business day as the default	
period_range([start, end, periods, freq, name])		Return a fixed frequency datetime index, with day (calendar) as the default	
timedelta_range([start, end, periods, freq, ...])	Return a fixed frequency timedelta index, with day as the default	
infer_freq(index[, warn])							Infer the most likely frequency given the input index.	



************************************************************************************************************
4. DATA FRAMES AND PANELS
************************************************************************************************************
CREATE DATA FRAMES
	You can create a data frame using:
		- Dict of 1D ndarrays, lists, dicts, or Series
		- 2-D numpy.ndarray
		- Structured or record ndarray
		- A Series
		- Another DataFrame

"DATA FRAME ATTRIBUTES"
T		Transpose index and columns	
at		Fast label-based scalar accessor	
axes	Return a list with the row axis labels and column axis labels as the only members.	
blocks	Internal property, property synonym for as_blocks()	
dtypes	Return the dtypes in this object.	
empty	True if NDFrame is entirely empty [no items], meaning any of the axes are of length 0.	
ftypes	Return the ftypes (indication of sparse/dense and dtype) in this object.	
iat		Fast integer location scalar accessor.	
iloc	Purely integer-location based indexing for selection by position.	
is_copy	|	
ix		A primarily label-location based indexer, with integer position fallback.	
loc		Purely label-location based indexer for selection by label.	
ndim	Number of axes / array dimensions	
shape	Return a tuple representing the dimensionality of the DataFrame.	
size	number of elements in the NDFrame	
style	Property returning a Styler object containing methods for building a styled HTML representation fo the DataFrame.	
values	Numpy representation of NDFrame	




------------------------------------------------------------------------------------------------------------------------------
SELECT, ADD, AND DELETE

#insert function 
	df.insert(POSITION_OF_COLUMN, "COLUMN NAME", COLUMN_LIST)
	cookbook_df.insert(1, "new column", [3,4,5,6])
------------------------------------------------------------------------------------------------------------------------------
INDEXING AND SELECTION

"OPERATION"						"SYNTAX"		"RESULT"
Select column					df[col]			Series
Select row by label				df.loc[label]	Series
Select row by integer			df.iloc[loc]	Series
Select rows						df[start:stop]	DataFrame
Select rows with boolean mask	df[mask]		DataFrame

produce_df.isin(['apples', 'onions'])

produce_df.where(produce_df > 'k')

------------------------------------------------------------------------------------------------------------------------------
NUMPY UNIVERSAL FUNCTIONS
------------------------------------------------------------------------------------------------------------------------------
CREATE PANELS

A Panel is a three-dimensional analogue of DataFrame. Each item (the analogue of columns in a DataFrame) in a Panel is a DataFrame.

The term "PANEL DATA" is derived from econometrics and is partially responsible for the name pandas: pan(el)-da(ta)-s. The names for the 3 axes within a panel are intended to give some semantic meaning to describing operations involving panel data and, in particular, econometric analysis of panel data. However, for the strict purposes of slicing and dicing a collection of DataFrame objects, you may find the axis names slightly arbitrary:

items: axis 0, each item corresponds to a DataFrame contained inside
major_axis: axis 1, it is the index (rows) of each of the DataFrames
minor_axis: axis 2, it is the columns of each of the DataFrames

************************************************************************************************************
5. PLOTTING
************************************************************************************************************
INLINE PLOTTING
------------------------------------------------------------------------------------------------------------------------------
FIGURES AND SUBPLOTS
------------------------------------------------------------------------------------------------------------------------------
MULTIPLE LINES IN A SINGLE PLOT
------------------------------------------------------------------------------------------------------------------------------
TICK MARKS, LABELS, AND GRIDS
------------------------------------------------------------------------------------------------------------------------------
PLOT ANNOTATIONS
------------------------------------------------------------------------------------------------------------------------------
DATAFRAME PLOTS
------------------------------------------------------------------------------------------------------------------------------